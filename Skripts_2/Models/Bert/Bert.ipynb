{"cells":[{"cell_type":"markdown","source":["# Bert experimenty"],"metadata":{"id":"0MKpdkvbJusW"},"id":"0MKpdkvbJusW"},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHJhNE8XSkGf","outputId":"b3aff750-e54e-4b3f-9abb-d50fcf82f5e6","executionInfo":{"status":"ok","timestamp":1713892308949,"user_tz":-120,"elapsed":2506,"user":{"displayName":"Sabína Mackovčáková","userId":"15587729232235249039"}}},"id":"PHJhNE8XSkGf","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"id":"211cb2c2-652d-4a89-9864-7d80151a7b5c","metadata":{"id":"211cb2c2-652d-4a89-9864-7d80151a7b5c"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import tensorflow as tf\n","from torch.utils.data import Dataset\n","import re\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, f1_score\n","from sklearn.preprocessing import LabelEncoder\n","from typing import Dict, List\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast,BertTokenizer, DistilBertTokenizerFast\n","from transformers import BertForSequenceClassification, Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer, AutoModelForMaskedLM"]},{"cell_type":"code","source":["# !pip install transformers[torch]\n","# !pip install accelerate -U\n","# !pip install transformers==4.30"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4OlcuUgD7Wf7","executionInfo":{"status":"ok","timestamp":1713892306447,"user_tz":-120,"elapsed":144379,"user":{"displayName":"Sabína Mackovčáková","userId":"15587729232235249039"}},"outputId":"232f6d9b-ca55-4b62-be52-4e939649c3ff"},"id":"4OlcuUgD7Wf7","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n","Collecting accelerate>=0.21.0 (from transformers[torch])\n","  Using cached accelerate-0.29.3-py3-none-any.whl (297 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch->transformers[torch])\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n","Successfully installed accelerate-0.29.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.22.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Collecting transformers==4.30\n","  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30) (2024.2.2)\n","Installing collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.19.1\n","    Uninstalling tokenizers-0.19.1:\n","      Successfully uninstalled tokenizers-0.19.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.40.0\n","    Uninstalling transformers-4.40.0:\n","      Successfully uninstalled transformers-4.40.0\n","Successfully installed tokenizers-0.13.3 transformers-4.30.0\n"]}]},{"cell_type":"markdown","source":["## Načítanie a príprava dát"],"metadata":{"id":"7GmkbrEeJ9D7"},"id":"7GmkbrEeJ9D7"},{"cell_type":"code","execution_count":null,"id":"4876858b-6771-4290-b209-5a21e7554048","metadata":{"id":"4876858b-6771-4290-b209-5a21e7554048"},"outputs":[],"source":["dataset = pd.read_csv('../Data/final_dataset_2_balanced.csv')"]},{"cell_type":"code","execution_count":null,"id":"32360bac-1d14-4a68-b388-3976a022bdf3","metadata":{"id":"32360bac-1d14-4a68-b388-3976a022bdf3"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(dataset['processed_text'], dataset['author_id'], test_size=0.2, random_state=42)\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"]},{"cell_type":"code","execution_count":null,"id":"2f966a51-54f9-4b32-941c-ad22463a8400","metadata":{"id":"2f966a51-54f9-4b32-941c-ad22463a8400"},"outputs":[],"source":["label_encoder = LabelEncoder()\n","\n","y_train = label_encoder.fit_transform(y_train)\n","y_valid = label_encoder.transform(y_valid)\n","y_test = label_encoder.transform(y_test)"]},{"cell_type":"markdown","id":"bc45a772-8ffd-4474-a794-01c90c6a8d37","metadata":{"id":"bc45a772-8ffd-4474-a794-01c90c6a8d37"},"source":["## Bert"]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"metadata":{"id":"JMOnvjaMIOtp"},"id":"JMOnvjaMIOtp","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_metrics(p):\n","    pred, labels = p\n","    pred = np.argmax(pred, axis=1)\n","\n","    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","    recall = recall_score(y_true=labels, y_pred=pred, average='macro')\n","    precision = precision_score(y_true=labels, y_pred=pred, average='macro')\n","    f1 = f1_score(y_true=labels, y_pred=pred, average='macro')\n","\n","    return {\n","        \"accuracy\": accuracy,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1\": f1\n","    }"],"metadata":{"id":"nzb3FQx9ILzf"},"id":"nzb3FQx9ILzf","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"6c1cc2db-a82c-4099-beec-ed68a8bf5818","metadata":{"id":"6c1cc2db-a82c-4099-beec-ed68a8bf5818"},"outputs":[],"source":["x_train = list(X_train)\n","x_val = list(X_valid)\n","x_test = list(X_test)\n","\n","y_train = list(y_train)\n","y_val = list(y_valid)\n","y_test = list(y_test)"]},{"cell_type":"code","execution_count":null,"id":"ec02ce0c-ee95-439b-959d-ad2b52145b37","metadata":{"id":"ec02ce0c-ee95-439b-959d-ad2b52145b37"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","train_encodings = tokenizer(x_train, truncation=True, padding=True)\n","val_encodings = tokenizer(x_val,truncation=True, padding=True)\n","test_encodings = tokenizer(x_test, truncation=True, padding=True)"]},{"cell_type":"code","source":["train_dataset = CustomDataset(train_encodings, y_train)\n","val_dataset = CustomDataset(val_encodings, y_valid)\n","test_dataset = CustomDataset(test_encodings, y_test)"],"metadata":{"id":"_y_bmuOqIFEl"},"id":"_y_bmuOqIFEl","execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels_count = len(dataset['author_id'].unique())\n","print(labels_count)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yHIfZamOZpsM","outputId":"68de5583-36b7-4a2c-d229-3c47d5e255df","executionInfo":{"status":"ok","timestamp":1713892711181,"user_tz":-120,"elapsed":14,"user":{"displayName":"Sabína Mackovčáková","userId":"15587729232235249039"}}},"id":"yHIfZamOZpsM","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["20\n"]}]},{"cell_type":"markdown","source":["## Experiment 1 - learning_rate = 5e-5"],"metadata":{"id":"N8BtVmU7CAdC"},"id":"N8BtVmU7CAdC"},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=12,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    warmup_steps=300,\n","    weight_decay=0.01,\n","    learning_rate=5e-5,             #default\n","    logging_dir='./logs',\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\",\n","    greater_is_better=True,\n","    fp16=True,\n",")\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=labels_count)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":767},"id":"uDNs0NkRMNX5","outputId":"02fe00c4-b802-43e3-85c3-8d3f97e52032","executionInfo":{"status":"ok","timestamp":1713894035744,"user_tz":-120,"elapsed":486702,"user":{"displayName":"Sabína Mackovčáková","userId":"15587729232235249039"}}},"id":"uDNs0NkRMNX5","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='648' max='648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [648/648 08:03, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>2.971659</td>\n","      <td>0.083333</td>\n","      <td>0.070720</td>\n","      <td>0.125758</td>\n","      <td>0.064096</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>2.829183</td>\n","      <td>0.104167</td>\n","      <td>0.017833</td>\n","      <td>0.098864</td>\n","      <td>0.027722</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>2.382121</td>\n","      <td>0.427083</td>\n","      <td>0.393494</td>\n","      <td>0.447392</td>\n","      <td>0.385307</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>2.073130</td>\n","      <td>0.479167</td>\n","      <td>0.521919</td>\n","      <td>0.539291</td>\n","      <td>0.437111</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>1.472418</td>\n","      <td>0.645833</td>\n","      <td>0.739881</td>\n","      <td>0.689767</td>\n","      <td>0.673403</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>No log</td>\n","      <td>1.126880</td>\n","      <td>0.677083</td>\n","      <td>0.728214</td>\n","      <td>0.735184</td>\n","      <td>0.693419</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>No log</td>\n","      <td>0.843350</td>\n","      <td>0.781250</td>\n","      <td>0.817100</td>\n","      <td>0.791147</td>\n","      <td>0.778077</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>No log</td>\n","      <td>0.826915</td>\n","      <td>0.791667</td>\n","      <td>0.811905</td>\n","      <td>0.809481</td>\n","      <td>0.784644</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>No log</td>\n","      <td>0.956209</td>\n","      <td>0.760417</td>\n","      <td>0.775830</td>\n","      <td>0.785671</td>\n","      <td>0.764191</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.486100</td>\n","      <td>0.884092</td>\n","      <td>0.760417</td>\n","      <td>0.743647</td>\n","      <td>0.776981</td>\n","      <td>0.743997</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>1.486100</td>\n","      <td>0.825358</td>\n","      <td>0.812500</td>\n","      <td>0.818647</td>\n","      <td>0.829481</td>\n","      <td>0.810584</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>1.486100</td>\n","      <td>0.816912</td>\n","      <td>0.802083</td>\n","      <td>0.824957</td>\n","      <td>0.819481</td>\n","      <td>0.811757</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=648, training_loss=1.1537413957678242, metrics={'train_runtime': 484.4315, 'train_samples_per_second': 21.353, 'train_steps_per_second': 1.338, 'total_flos': 2722060610666496.0, 'train_loss': 1.1537413957678242, 'epoch': 12.0})"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":503},"id":"7Um09ZxHCAdD","outputId":"2e1028fe-41fb-4516-f79d-9c76dbf7a505","executionInfo":{"status":"ok","timestamp":1713894038455,"user_tz":-120,"elapsed":2718,"user":{"displayName":"Sabína Mackovčáková","userId":"15587729232235249039"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["PredictionOutput(predictions=array([[-0.7402344 ,  0.5058594 ,  6.9765625 , ...,  0.13659668,\n","         0.49658203, -0.4663086 ],\n","       [ 0.7348633 ,  0.47436523, -1.5703125 , ..., -1.4023438 ,\n","        -0.9394531 , -0.4873047 ],\n","       [-1.1621094 , -0.6645508 ,  0.8310547 , ..., -0.85595703,\n","         0.6196289 , -0.6557617 ],\n","       ...,\n","       [ 4.5820312 ,  0.171875  , -0.47680664, ..., -1.1650391 ,\n","        -0.8925781 , -0.66308594],\n","       [-0.5620117 ,  1.6005859 ,  6.9570312 , ...,  0.31713867,\n","         0.0333252 , -0.7294922 ],\n","       [-0.06744385, -0.6953125 , -1.1855469 , ..., -1.1894531 ,\n","        -0.6308594 ,  0.1104126 ]], dtype=float32), label_ids=array([ 2,  5, 16,  3,  4,  1, 19, 17, 13, 11,  1,  4,  4, 11,  9, 10, 12,\n","        8,  1,  3, 13,  7,  6, 19, 16,  9,  6,  0, 19,  7, 13, 14,  6,  8,\n","       13,  0,  3, 16, 19,  7, 17, 16,  5, 19, 11, 19, 19,  4,  4,  9,  8,\n","       14, 13, 10, 11, 19,  5,  5, 18, 13, 19, 10, 15, 16, 10,  8,  4,  3,\n","        0, 12,  3, 10,  2,  4, 16,  3, 15,  4, 18, 11,  2, 15, 11, 16,  0,\n","        2, 17, 10, 17,  7, 12,  3,  9, 13, 11,  6, 12, 18,  9, 10,  0, 10,\n","        8, 16, 11,  8, 17, 18,  1, 18, 13, 11, 10,  5,  7,  8,  9, 10,  8,\n","       15, 12,  1, 18, 17, 13,  2, 19, 10,  6,  7,  9,  2, 19, 15, 17,  7,\n","        7, 12,  3, 18,  1,  7, 13,  7, 17, 12,  6,  6,  0, 12, 18, 19,  8,\n","       15,  2,  3, 19,  9, 14, 19, 18, 18,  5,  9,  9, 11, 16, 11,  1,  4,\n","        8, 18, 19,  9, 15,  0, 10,  2, 16,  1,  8,  1, 15, 17,  9, 14, 12,\n","        1,  3, 12, 18,  6,  4, 11,  3, 15,  4, 18,  5,  9,  1, 11,  7, 17,\n","       17, 15,  1,  6,  6, 14, 14,  1, 13,  5, 18,  9,  7,  9,  6,  0,  5,\n","        5, 11,  5,  9, 12,  2, 16, 15,  7, 19, 10, 11,  7,  5, 13, 11,  0,\n","        2, 11]), metrics={'test_loss': 0.8235411047935486, 'test_accuracy': 0.8, 'test_precision': 0.8114339826839826, 'test_recall': 0.7936966505716505, 'test_f1': 0.7958255494962152, 'test_runtime': 2.8636, 'test_samples_per_second': 83.81, 'test_steps_per_second': 5.238})"]},"metadata":{},"execution_count":43}],"source":["trainer.predict(test_dataset)"],"id":"7Um09ZxHCAdD"},{"cell_type":"markdown","source":["## Experiment 4 - learning_rate = 8e-5"],"metadata":{"id":"osiiekt4ad2h"},"id":"osiiekt4ad2h"},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":732},"outputId":"28c06591-bfd9-4fe3-d2ac-3c80f916feb4","id":"0enmFfxEad2i","executionInfo":{"status":"ok","timestamp":1713893544987,"user_tz":-120,"elapsed":495641,"user":{"displayName":"Sabína Mackovčáková","userId":"15587729232235249039"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='648' max='648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [648/648 08:10, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>2.974833</td>\n","      <td>0.062500</td>\n","      <td>0.060498</td>\n","      <td>0.071688</td>\n","      <td>0.030519</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>2.741608</td>\n","      <td>0.250000</td>\n","      <td>0.267004</td>\n","      <td>0.304643</td>\n","      <td>0.224802</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>2.038671</td>\n","      <td>0.437500</td>\n","      <td>0.514710</td>\n","      <td>0.482186</td>\n","      <td>0.377606</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>1.573408</td>\n","      <td>0.552083</td>\n","      <td>0.698564</td>\n","      <td>0.609508</td>\n","      <td>0.549903</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>1.098896</td>\n","      <td>0.656250</td>\n","      <td>0.731484</td>\n","      <td>0.685801</td>\n","      <td>0.673360</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>No log</td>\n","      <td>0.859665</td>\n","      <td>0.750000</td>\n","      <td>0.801349</td>\n","      <td>0.776245</td>\n","      <td>0.753384</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>No log</td>\n","      <td>0.785474</td>\n","      <td>0.770833</td>\n","      <td>0.771742</td>\n","      <td>0.772457</td>\n","      <td>0.758418</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>No log</td>\n","      <td>0.834776</td>\n","      <td>0.781250</td>\n","      <td>0.784919</td>\n","      <td>0.794085</td>\n","      <td>0.774060</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>No log</td>\n","      <td>0.815626</td>\n","      <td>0.822917</td>\n","      <td>0.824167</td>\n","      <td>0.829048</td>\n","      <td>0.809945</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.286400</td>\n","      <td>0.819784</td>\n","      <td>0.843750</td>\n","      <td>0.872500</td>\n","      <td>0.841645</td>\n","      <td>0.841146</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>1.286400</td>\n","      <td>0.822343</td>\n","      <td>0.833333</td>\n","      <td>0.857083</td>\n","      <td>0.842835</td>\n","      <td>0.838734</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>1.286400</td>\n","      <td>0.819747</td>\n","      <td>0.833333</td>\n","      <td>0.857083</td>\n","      <td>0.842835</td>\n","      <td>0.838734</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=648, training_loss=0.995923587569484, metrics={'train_runtime': 490.951, 'train_samples_per_second': 21.069, 'train_steps_per_second': 1.32, 'total_flos': 2722060610666496.0, 'train_loss': 0.995923587569484, 'epoch': 12.0})"]},"metadata":{},"execution_count":40}],"source":["training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=12,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    warmup_steps=300,\n","    weight_decay=0.01,\n","    learning_rate=8e-5,\n","    logging_dir='./logs',\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\",\n","    greater_is_better=True,\n","    fp16=True,\n",")\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=labels_count)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"],"id":"0enmFfxEad2i"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":503},"id":"IzgTIkvCad2i","outputId":"7ac16599-875b-4790-c87e-28914019b438","executionInfo":{"status":"ok","timestamp":1713893549046,"user_tz":-120,"elapsed":3173,"user":{"displayName":"Sabína Mackovčáková","userId":"15587729232235249039"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["PredictionOutput(predictions=array([[ 0.09423828,  3.1914062 ,  7.046875  , ...,  0.01707458,\n","        -0.9189453 , -1.0449219 ],\n","       [-0.2253418 ,  0.41088867, -1.8085938 , ..., -1.4345703 ,\n","         0.47558594, -0.31274414],\n","       [ 0.42822266, -1.8330078 ,  0.93603516, ..., -0.54248047,\n","         0.7788086 , -1.0654297 ],\n","       ...,\n","       [ 4.5976562 ,  0.2397461 , -1.2568359 , ..., -1.2539062 ,\n","         0.9848633 , -0.96777344],\n","       [ 0.90234375,  7.1875    ,  3.0742188 , ...,  0.05117798,\n","        -1.5283203 , -1.2285156 ],\n","       [-0.19030762, -0.2565918 , -0.8857422 , ..., -0.25976562,\n","         0.23034668, -0.16296387]], dtype=float32), label_ids=array([ 2,  5, 16,  3,  4,  1, 19, 17, 13, 11,  1,  4,  4, 11,  9, 10, 12,\n","        8,  1,  3, 13,  7,  6, 19, 16,  9,  6,  0, 19,  7, 13, 14,  6,  8,\n","       13,  0,  3, 16, 19,  7, 17, 16,  5, 19, 11, 19, 19,  4,  4,  9,  8,\n","       14, 13, 10, 11, 19,  5,  5, 18, 13, 19, 10, 15, 16, 10,  8,  4,  3,\n","        0, 12,  3, 10,  2,  4, 16,  3, 15,  4, 18, 11,  2, 15, 11, 16,  0,\n","        2, 17, 10, 17,  7, 12,  3,  9, 13, 11,  6, 12, 18,  9, 10,  0, 10,\n","        8, 16, 11,  8, 17, 18,  1, 18, 13, 11, 10,  5,  7,  8,  9, 10,  8,\n","       15, 12,  1, 18, 17, 13,  2, 19, 10,  6,  7,  9,  2, 19, 15, 17,  7,\n","        7, 12,  3, 18,  1,  7, 13,  7, 17, 12,  6,  6,  0, 12, 18, 19,  8,\n","       15,  2,  3, 19,  9, 14, 19, 18, 18,  5,  9,  9, 11, 16, 11,  1,  4,\n","        8, 18, 19,  9, 15,  0, 10,  2, 16,  1,  8,  1, 15, 17,  9, 14, 12,\n","        1,  3, 12, 18,  6,  4, 11,  3, 15,  4, 18,  5,  9,  1, 11,  7, 17,\n","       17, 15,  1,  6,  6, 14, 14,  1, 13,  5, 18,  9,  7,  9,  6,  0,  5,\n","        5, 11,  5,  9, 12,  2, 16, 15,  7, 19, 10, 11,  7,  5, 13, 11,  0,\n","        2, 11]), metrics={'test_loss': 1.0105174779891968, 'test_accuracy': 0.775, 'test_precision': 0.8021406579746362, 'test_recall': 0.7634455821955821, 'test_f1': 0.7679021522644167, 'test_runtime': 2.9627, 'test_samples_per_second': 81.006, 'test_steps_per_second': 5.063})"]},"metadata":{},"execution_count":41}],"source":["trainer.predict(test_dataset)"],"id":"IzgTIkvCad2i"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0rc1"},"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}