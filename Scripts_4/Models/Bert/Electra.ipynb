{"cells":[{"cell_type":"markdown","source":["# Electra experimenty"],"metadata":{"id":"0MKpdkvbJusW"},"id":"0MKpdkvbJusW"},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHJhNE8XSkGf","outputId":"49ffd2c0-9168-43ca-dca0-c271d1b7d885","executionInfo":{"status":"ok","timestamp":1713963981762,"user_tz":-120,"elapsed":2093,"user":{"displayName":"Sabína Mackovčáková","userId":"15587729232235249039"}}},"id":"PHJhNE8XSkGf","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"id":"211cb2c2-652d-4a89-9864-7d80151a7b5c","metadata":{"id":"211cb2c2-652d-4a89-9864-7d80151a7b5c"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import tensorflow as tf\n","from torch.utils.data import Dataset\n","import re\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, f1_score\n","from sklearn.preprocessing import LabelEncoder\n","from typing import Dict, List\n","import transformers\n","from transformers import ElectraModel, ElectraConfig, ElectraTokenizer, ElectraForSequenceClassification\n","from transformers import Trainer, TrainingArguments\n"]},{"cell_type":"code","source":["# !pip install transformers[torch]\n","# !pip install accelerate -U\n","# !pip install transformers==4.30"],"metadata":{"id":"UX_4STYsuLkK"},"id":"UX_4STYsuLkK","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Načítanie a príprava dát"],"metadata":{"id":"7GmkbrEeJ9D7"},"id":"7GmkbrEeJ9D7"},{"cell_type":"code","execution_count":null,"id":"4876858b-6771-4290-b209-5a21e7554048","metadata":{"id":"4876858b-6771-4290-b209-5a21e7554048"},"outputs":[],"source":["dataset = pd.read_csv('../Data/final_dataset_4.csv')"]},{"cell_type":"code","execution_count":null,"id":"32360bac-1d14-4a68-b388-3976a022bdf3","metadata":{"id":"32360bac-1d14-4a68-b388-3976a022bdf3"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(dataset['processed_text'], dataset['author_id'], test_size=0.2, random_state=42)\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"]},{"cell_type":"code","execution_count":null,"id":"2f966a51-54f9-4b32-941c-ad22463a8400","metadata":{"id":"2f966a51-54f9-4b32-941c-ad22463a8400"},"outputs":[],"source":["label_encoder = LabelEncoder()\n","\n","y_train = label_encoder.fit_transform(y_train)\n","y_valid = label_encoder.transform(y_valid)\n","y_test = label_encoder.transform(y_test)"]},{"cell_type":"markdown","id":"bc45a772-8ffd-4474-a794-01c90c6a8d37","metadata":{"id":"bc45a772-8ffd-4474-a794-01c90c6a8d37"},"source":["## Electra"]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"metadata":{"id":"JMOnvjaMIOtp"},"id":"JMOnvjaMIOtp","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_metrics(p):\n","    pred, labels = p\n","    pred = np.argmax(pred, axis=1)\n","\n","    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","    recall = recall_score(y_true=labels, y_pred=pred, average='macro', zero_division=0)\n","    precision = precision_score(y_true=labels, y_pred=pred, average='macro', zero_division=0)\n","    f1 = f1_score(y_true=labels, y_pred=pred, average='macro')\n","\n","    return {\n","        \"accuracy\": accuracy,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1\": f1\n","    }"],"metadata":{"id":"nzb3FQx9ILzf"},"id":"nzb3FQx9ILzf","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"6c1cc2db-a82c-4099-beec-ed68a8bf5818","metadata":{"id":"6c1cc2db-a82c-4099-beec-ed68a8bf5818"},"outputs":[],"source":["x_train = list(X_train)\n","x_val = list(X_valid)\n","x_test = list(X_test)\n","\n","y_train = list(y_train)\n","y_val = list(y_valid)\n","y_test = list(y_test)"]},{"cell_type":"code","execution_count":null,"id":"ec02ce0c-ee95-439b-959d-ad2b52145b37","metadata":{"id":"ec02ce0c-ee95-439b-959d-ad2b52145b37","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713964310734,"user_tz":-120,"elapsed":310673,"user":{"displayName":"Sabína Mackovčáková","userId":"15587729232235249039"}},"outputId":"49a36d74-a025-403f-8bf5-11fc1b5ba288"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n","train_encodings = tokenizer(x_train, truncation=True, padding=True)\n","val_encodings = tokenizer(x_val,truncation=True, padding=True)\n","test_encodings = tokenizer(x_test, truncation=True, padding=True)"]},{"cell_type":"code","source":["train_dataset = CustomDataset(train_encodings, y_train)\n","val_dataset = CustomDataset(val_encodings, y_valid)\n","test_dataset = CustomDataset(test_encodings, y_test)"],"metadata":{"id":"_y_bmuOqIFEl"},"id":"_y_bmuOqIFEl","execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels_count = len(dataset['author_id'].unique())\n","print(labels_count)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yHIfZamOZpsM","outputId":"1b5695a7-b5c9-44a9-9f85-9c82a2a4fa7f","executionInfo":{"status":"ok","timestamp":1713964310735,"user_tz":-120,"elapsed":17,"user":{"displayName":"Sabína Mackovčáková","userId":"15587729232235249039"}}},"id":"yHIfZamOZpsM","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["20\n"]}]},{"cell_type":"markdown","source":["## Experiment 1 - learning_rate = 5e-5"],"metadata":{"id":"N8BtVmU7CAdC"},"id":"N8BtVmU7CAdC"},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=15,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    weight_decay=0.01,\n","    learning_rate=5e-5,             #default\n","    logging_dir='./logs',\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\",\n","    greater_is_better=True,\n","    fp16=True,\n",")\n","\n","model = ElectraForSequenceClassification.from_pretrained(\"google/electra-small-discriminator\", num_labels=labels_count)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":776,"referenced_widgets":["5941b0b629424cb5a146199f314a2b2d","e6eeadde3d1e485b8fbed77f1a9a8d09","fa72724c49a64fe4b890e5795c2d7221","0447ea6a869243f4b72b2f6917a5e5e5","09407577a44144f5ae9c6f71a09149b3","4e9a4cd7945a423caca044f63d35efe7","305df7f3fe284b46ad47ee704dbf35e5","bbd2abc6642e455c826d397dd1413bdb","a34b937b7fb747b4bd2b170143e2fb4b","014d2c2eebeb42faa1d8161c63d3d1db","64a0428031f64f8d87d3cf3925479e21"]},"id":"uDNs0NkRMNX5","outputId":"36d184e5-adb5-4130-a81e-267f1644c6d1","executionInfo":{"status":"ok","timestamp":1713964496158,"user_tz":-120,"elapsed":185437,"user":{"displayName":"Sabína Mackovčáková","userId":"15587729232235249039"}}},"id":"uDNs0NkRMNX5","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/54.2M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5941b0b629424cb5a146199f314a2b2d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1635' max='1635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1635/1635 03:01, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>2.956568</td>\n","      <td>0.103093</td>\n","      <td>0.062237</td>\n","      <td>0.095000</td>\n","      <td>0.030237</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>2.829595</td>\n","      <td>0.195876</td>\n","      <td>0.107765</td>\n","      <td>0.199643</td>\n","      <td>0.123857</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>2.691789</td>\n","      <td>0.288660</td>\n","      <td>0.200805</td>\n","      <td>0.304762</td>\n","      <td>0.218083</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>2.586230</td>\n","      <td>0.288660</td>\n","      <td>0.204508</td>\n","      <td>0.320952</td>\n","      <td>0.228136</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>2.740400</td>\n","      <td>2.452994</td>\n","      <td>0.340206</td>\n","      <td>0.231378</td>\n","      <td>0.371548</td>\n","      <td>0.258398</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>2.740400</td>\n","      <td>2.371184</td>\n","      <td>0.402062</td>\n","      <td>0.357792</td>\n","      <td>0.457262</td>\n","      <td>0.352449</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>2.740400</td>\n","      <td>2.248218</td>\n","      <td>0.422680</td>\n","      <td>0.349657</td>\n","      <td>0.477024</td>\n","      <td>0.373245</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>2.740400</td>\n","      <td>2.183438</td>\n","      <td>0.402062</td>\n","      <td>0.370129</td>\n","      <td>0.448690</td>\n","      <td>0.363114</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>2.740400</td>\n","      <td>2.090372</td>\n","      <td>0.402062</td>\n","      <td>0.399286</td>\n","      <td>0.461190</td>\n","      <td>0.386057</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>2.000800</td>\n","      <td>2.071435</td>\n","      <td>0.402062</td>\n","      <td>0.390055</td>\n","      <td>0.467857</td>\n","      <td>0.376982</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>2.000800</td>\n","      <td>2.018122</td>\n","      <td>0.412371</td>\n","      <td>0.386154</td>\n","      <td>0.480714</td>\n","      <td>0.401372</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>2.000800</td>\n","      <td>1.986711</td>\n","      <td>0.422680</td>\n","      <td>0.424716</td>\n","      <td>0.487857</td>\n","      <td>0.419690</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>2.000800</td>\n","      <td>1.980066</td>\n","      <td>0.422680</td>\n","      <td>0.422732</td>\n","      <td>0.487857</td>\n","      <td>0.415839</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>1.410900</td>\n","      <td>1.962984</td>\n","      <td>0.453608</td>\n","      <td>0.473248</td>\n","      <td>0.522857</td>\n","      <td>0.454007</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>1.410900</td>\n","      <td>1.955282</td>\n","      <td>0.474227</td>\n","      <td>0.487146</td>\n","      <td>0.542857</td>\n","      <td>0.474623</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1635, training_loss=1.9836382384693951, metrics={'train_runtime': 183.7421, 'train_samples_per_second': 71.105, 'train_steps_per_second': 8.898, 'total_flos': 384553275125760.0, 'train_loss': 1.9836382384693951, 'epoch': 15.0})"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":553},"id":"7Um09ZxHCAdD","outputId":"6665ceca-061f-41ab-8c1f-fa2de4b7d552","executionInfo":{"status":"ok","timestamp":1713964497168,"user_tz":-120,"elapsed":1023,"user":{"displayName":"Sabína Mackovčáková","userId":"15587729232235249039"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["PredictionOutput(predictions=array([[-1.90625   , -1.3212891 , -1.1796875 , ..., -1.9765625 ,\n","         1.5048828 ,  1.0332031 ],\n","       [-0.9926758 , -0.49072266, -0.05389404, ..., -1.8662109 ,\n","         0.7988281 ,  1.6152344 ],\n","       [-0.6665039 , -0.8857422 , -0.9785156 , ..., -1.0224609 ,\n","        -0.5053711 ,  1.4921875 ],\n","       ...,\n","       [-1.4570312 , -0.8364258 , -0.39013672, ..., -2.0996094 ,\n","         1.3251953 ,  1.5019531 ],\n","       [-0.55078125, -0.7988281 , -1.1308594 , ..., -0.30395508,\n","        -0.9267578 ,  0.36132812],\n","       [-1.5791016 , -0.8330078 , -0.5722656 , ..., -1.9912109 ,\n","         2.3027344 ,  0.7426758 ]], dtype=float32), label_ids=array([16,  3, 19, 16,  7, 18, 15,  4, 17,  2, 11,  5, 10,  0, 11, 16,  9,\n","       15,  9,  0, 10, 11,  5, 13,  8,  1, 10, 13,  0,  0,  8, 13,  8, 19,\n","       13,  2, 14,  4,  5,  0,  5,  7, 12, 10,  5, 16,  6, 16,  2,  1, 10,\n","        9, 12, 11,  6,  6,  4,  0,  3, 10,  4,  4, 19,  0, 13, 17, 13,  5,\n","        3,  7, 15, 19, 16,  2,  5,  4,  3,  1, 11, 12,  8, 17, 13, 18,  4,\n","        8, 14,  1,  4, 16, 12,  9,  0,  2, 15, 13,  5,  7,  9,  8, 15, 13,\n","        7, 17,  9,  2,  6,  3, 19, 11,  0, 17, 11,  8, 16, 15, 14, 19,  3,\n","        9,  0,  8, 16,  3, 17,  2,  5, 18, 17,  8,  9, 10,  8, 15,  7, 18,\n","       12, 13, 14,  3, 11,  9,  6,  9, 11, 19,  8, 14, 13, 10, 17,  5,  1,\n","       10, 18,  9,  0, 11,  5, 15, 12, 18, 19, 10, 13,  0,  9,  8, 10,  1,\n","        5, 10, 17,  7,  3, 18,  1,  3,  5, 15, 15,  3,  6,  8,  6,  5, 11,\n","       17,  7, 16,  1,  2, 10,  4, 14, 11, 13,  6, 12, 19, 12,  3, 16,  7,\n","        0,  2, 15, 17,  1,  3,  2,  8, 12, 15, 19, 12,  4, 12,  2,  9,  4,\n","       11, 16,  9, 14,  6, 19,  6, 12,  9, 14,  1, 18, 19,  9, 19, 14, 19,\n","        6, 18,  9, 18]), metrics={'test_loss': 1.712738275527954, 'test_accuracy': 0.512396694214876, 'test_precision': 0.5532584776334776, 'test_recall': 0.5135791659321072, 'test_f1': 0.4846852301739375, 'test_runtime': 0.9648, 'test_samples_per_second': 250.835, 'test_steps_per_second': 32.132})"]},"metadata":{},"execution_count":15}],"source":["trainer.predict(test_dataset)"],"id":"7Um09ZxHCAdD"},{"cell_type":"markdown","source":["## Experiment 4 - learning_rate = 8e-5"],"metadata":{"id":"osiiekt4ad2h"},"id":"osiiekt4ad2h"},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":650},"outputId":"609aae4a-be85-40c1-b137-89624ef8aa06","id":"0enmFfxEad2i","executionInfo":{"status":"ok","timestamp":1713964625616,"user_tz":-120,"elapsed":128450,"user":{"displayName":"Sabína Mackovčáková","userId":"15587729232235249039"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='660' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [660/660 02:07, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>2.990496</td>\n","      <td>0.072165</td>\n","      <td>0.010874</td>\n","      <td>0.061667</td>\n","      <td>0.017376</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>2.978354</td>\n","      <td>0.103093</td>\n","      <td>0.011531</td>\n","      <td>0.090000</td>\n","      <td>0.020303</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>2.906351</td>\n","      <td>0.257732</td>\n","      <td>0.149316</td>\n","      <td>0.301310</td>\n","      <td>0.176133</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>2.779196</td>\n","      <td>0.309278</td>\n","      <td>0.296786</td>\n","      <td>0.339643</td>\n","      <td>0.264364</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>2.617640</td>\n","      <td>0.309278</td>\n","      <td>0.209046</td>\n","      <td>0.368095</td>\n","      <td>0.245052</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>No log</td>\n","      <td>2.521011</td>\n","      <td>0.268041</td>\n","      <td>0.220337</td>\n","      <td>0.323333</td>\n","      <td>0.212148</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>No log</td>\n","      <td>2.293945</td>\n","      <td>0.391753</td>\n","      <td>0.358914</td>\n","      <td>0.456905</td>\n","      <td>0.360893</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>No log</td>\n","      <td>2.152127</td>\n","      <td>0.412371</td>\n","      <td>0.485918</td>\n","      <td>0.482619</td>\n","      <td>0.395585</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>No log</td>\n","      <td>2.040834</td>\n","      <td>0.432990</td>\n","      <td>0.432662</td>\n","      <td>0.487262</td>\n","      <td>0.413146</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>2.535200</td>\n","      <td>1.951011</td>\n","      <td>0.443299</td>\n","      <td>0.474835</td>\n","      <td>0.498571</td>\n","      <td>0.433296</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>2.535200</td>\n","      <td>1.928565</td>\n","      <td>0.453608</td>\n","      <td>0.436561</td>\n","      <td>0.515000</td>\n","      <td>0.443789</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>2.535200</td>\n","      <td>1.895533</td>\n","      <td>0.453608</td>\n","      <td>0.490000</td>\n","      <td>0.510000</td>\n","      <td>0.442410</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=660, training_loss=2.291194707697088, metrics={'train_runtime': 127.5575, 'train_samples_per_second': 81.94, 'train_steps_per_second': 5.174, 'total_flos': 307642620100608.0, 'train_loss': 2.291194707697088, 'epoch': 12.0})"]},"metadata":{},"execution_count":16}],"source":["training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=12,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    warmup_steps=300,\n","    weight_decay=0.01,\n","    learning_rate=8e-5,\n","    logging_dir='./logs',\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\",\n","    greater_is_better=True,\n","    fp16=True,\n",")\n","\n","model = ElectraForSequenceClassification.from_pretrained(\"google/electra-small-discriminator\", num_labels=labels_count)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"],"id":"0enmFfxEad2i"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":553},"id":"IzgTIkvCad2i","outputId":"5d233788-be95-4e28-d607-ad40d775d00d","executionInfo":{"status":"ok","timestamp":1713964626534,"user_tz":-120,"elapsed":921,"user":{"displayName":"Sabína Mackovčáková","userId":"15587729232235249039"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["PredictionOutput(predictions=array([[-0.42919922, -0.03207397, -0.6274414 , ...,  0.6557617 ,\n","         0.02593994, -0.48950195],\n","       [ 0.7861328 ,  0.90478516,  0.96777344, ..., -1.1660156 ,\n","        -0.8286133 , -0.19592285],\n","       [-1.3730469 , -0.9194336 , -1.4794922 , ...,  0.21240234,\n","        -0.23022461,  1.8388672 ],\n","       ...,\n","       [-1.0537109 , -0.28320312, -0.91064453, ...,  0.10693359,\n","         0.76220703,  1.1503906 ],\n","       [-1.4541016 , -1.0263672 , -1.6289062 , ...,  0.43286133,\n","        -0.28173828,  1.8330078 ],\n","       [-0.49902344,  0.5366211 ,  0.30566406, ..., -1.0175781 ,\n","         1.6210938 , -0.08215332]], dtype=float32), label_ids=array([16,  3, 19, 16,  7, 18, 15,  4, 17,  2, 11,  5, 10,  0, 11, 16,  9,\n","       15,  9,  0, 10, 11,  5, 13,  8,  1, 10, 13,  0,  0,  8, 13,  8, 19,\n","       13,  2, 14,  4,  5,  0,  5,  7, 12, 10,  5, 16,  6, 16,  2,  1, 10,\n","        9, 12, 11,  6,  6,  4,  0,  3, 10,  4,  4, 19,  0, 13, 17, 13,  5,\n","        3,  7, 15, 19, 16,  2,  5,  4,  3,  1, 11, 12,  8, 17, 13, 18,  4,\n","        8, 14,  1,  4, 16, 12,  9,  0,  2, 15, 13,  5,  7,  9,  8, 15, 13,\n","        7, 17,  9,  2,  6,  3, 19, 11,  0, 17, 11,  8, 16, 15, 14, 19,  3,\n","        9,  0,  8, 16,  3, 17,  2,  5, 18, 17,  8,  9, 10,  8, 15,  7, 18,\n","       12, 13, 14,  3, 11,  9,  6,  9, 11, 19,  8, 14, 13, 10, 17,  5,  1,\n","       10, 18,  9,  0, 11,  5, 15, 12, 18, 19, 10, 13,  0,  9,  8, 10,  1,\n","        5, 10, 17,  7,  3, 18,  1,  3,  5, 15, 15,  3,  6,  8,  6,  5, 11,\n","       17,  7, 16,  1,  2, 10,  4, 14, 11, 13,  6, 12, 19, 12,  3, 16,  7,\n","        0,  2, 15, 17,  1,  3,  2,  8, 12, 15, 19, 12,  4, 12,  2,  9,  4,\n","       11, 16,  9, 14,  6, 19,  6, 12,  9, 14,  1, 18, 19,  9, 19, 14, 19,\n","        6, 18,  9, 18]), metrics={'test_loss': 1.758895993232727, 'test_accuracy': 0.5537190082644629, 'test_precision': 0.5572284264583025, 'test_recall': 0.5505573674691322, 'test_f1': 0.5262371514607348, 'test_runtime': 0.8977, 'test_samples_per_second': 269.588, 'test_steps_per_second': 17.824})"]},"metadata":{},"execution_count":17}],"source":["trainer.predict(test_dataset)"],"id":"IzgTIkvCad2i"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0rc1"},"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5941b0b629424cb5a146199f314a2b2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e6eeadde3d1e485b8fbed77f1a9a8d09","IPY_MODEL_fa72724c49a64fe4b890e5795c2d7221","IPY_MODEL_0447ea6a869243f4b72b2f6917a5e5e5"],"layout":"IPY_MODEL_09407577a44144f5ae9c6f71a09149b3"}},"e6eeadde3d1e485b8fbed77f1a9a8d09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e9a4cd7945a423caca044f63d35efe7","placeholder":"​","style":"IPY_MODEL_305df7f3fe284b46ad47ee704dbf35e5","value":"pytorch_model.bin: 100%"}},"fa72724c49a64fe4b890e5795c2d7221":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbd2abc6642e455c826d397dd1413bdb","max":54245363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a34b937b7fb747b4bd2b170143e2fb4b","value":54245363}},"0447ea6a869243f4b72b2f6917a5e5e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_014d2c2eebeb42faa1d8161c63d3d1db","placeholder":"​","style":"IPY_MODEL_64a0428031f64f8d87d3cf3925479e21","value":" 54.2M/54.2M [00:00&lt;00:00, 105MB/s]"}},"09407577a44144f5ae9c6f71a09149b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e9a4cd7945a423caca044f63d35efe7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"305df7f3fe284b46ad47ee704dbf35e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbd2abc6642e455c826d397dd1413bdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a34b937b7fb747b4bd2b170143e2fb4b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"014d2c2eebeb42faa1d8161c63d3d1db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64a0428031f64f8d87d3cf3925479e21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}